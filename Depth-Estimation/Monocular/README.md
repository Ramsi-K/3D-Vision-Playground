## Monocular Depth Estimation

[Monocular depth estimation](https://paperswithcode.com/task/monocular-depth-estimation) is the task of predicting the depth of a scene from *a single image*. Often, depth information is necessary for downstream tasks, such as 3D reconstruction or scene understanding. However, depth sensors are expensive and not always available.

This is a challenging task because depth is inherently ambiguous from a single image. The same scene can be projected onto the image plane in many different ways, and it is impossible to know which one is correct without additional information.

If you have multiple cameras, you can use [stereo depth estimation](https://paperswithcode.com/task/stereo-depth-estimation) techniques. But in some real world scenarios, you may be constrained to a single camera. When this is the case, you must rely on other cues, such as object size, occlusion, and perspective.

### Applications

Monocular depth estimation has many applications in computer vision. For example, it can be used for:

- **3D reconstruction**: Given a single image, estimate the depth of the scene and reconstruct the 3D geometry of the scene.
- **Scene understanding**: Given a single image, estimate the depth of the scene and use it to understand the scene better.
- **Autonomous driving**: Given a single image, estimate the depth of the scene and use it to navigate the vehicle.
- **Augmented reality**: Given a single image, estimate the depth of the scene and use it to place virtual objects in the scene.

Beyond these industry applications, the ability to extract high-quality depth information from a single image has found fascinating use cases in content creation and editing, for instance:

- **Image editing**: Given a single image, estimate the depth of the scene and use it to apply depth-aware effects to the image.
- **Image generation**: Given a single image, estimate the depth of the scene and use it to generate a 3D model of the scene.
- **Depth-map guided text-to-image generation**: Given a single image, estimate the depth of the scene and use it to generate a new image that both adheres to your input text prompt and has the same depth map. (See [ControlNet](https://huggingface.co/lllyasviel/sd-controlnet-depth)!)

Depth estimation is the process of measuring the distance of each pixel in an image relative to the camera. It's also known as the inverse problem. Depth estimation can be done from either monocular (single) or stereo (multiple views of a scene) images.

### Key Challenges with Monocular Depth Estimation

#### Data quality and quantity

Ground truth data is hard to come by, and is often noisy. For example, the SUN RGB-D dataset contains 10,335 RGB-D images, which is a lot, but it is still a relatively small dataset compared to other datasets such as ImageNet, which contains 1.2 million images. And in many cases, the ground truth data is noisy. For example, the ground truth depth maps in the SUN RGB-D dataset are generated by projecting the 3D point clouds onto the 2D image plane, and then computing the Euclidean distance between the projected points and the camera. This process is inherently noisy, and the resulting depth maps are often noisy as well.

#### Poor generalization

Models often struggle to generalize to new environments. Outdoors, for example, is a very different environment than indoors, and models trained on indoor data often fail to generalize to outdoor data.

#### Precarious metrics

Metrics are not always a good indicator of model performance. For example, a model might have a low RMSE, but still produce very noisy depth maps. This is why it is important to look at the depth maps themselves, and not just the metrics!

## [Voxel51 Tutorial](monocular_depth_estimation.ipynb)

### Tasks

Monocular Depth Estimation with HuggingFace Transformers.

- Model 1: Transformer Based DPT
- Model 2: Diffusion Based Marigold.

### Dataset

The [SUN RGB-D](https://rgbd.cs.princeton.edu/) dataset contains 10,335 RGB-D images, each of which has a corresponding RGB image, depth image, and camera intrinsics. It contains images from the NYU depth v2, Berkeley B3DO, and SUN3D datasets. SUN RGB-D is one of the most popular datasets for monocular depth estimation and semantic segmentation tasks!

## Resources

- [Monocular Depth in the Real World](https://medium.com/toyotaresearch/monocular-depth-in-the-real-world-99c2b287df34)

- [Awesome-Monocular-Depth](https://github.com/choyingw/Awesome-Monocular-Depth)
